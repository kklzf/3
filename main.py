from langchain.document_loaders import UnstructuredWordDocumentLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
import pinecone #å‘é‡æ•°æ®åº“
import os
from keys import OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_API_ENV
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain.vectorstores import Pinecone
import streamlit as st #ç½‘ç«™åˆ›å»º
import gtts #æ–‡å­—è½¬è¯­éŸ³

#'''
#ä¸‹é¢çš„è¿™éƒ¨åˆ†ä»£ç æ˜¯å°†æ–‡ä»¶å¤¹ä¸­çš„wordæ–‡æ¡£ï¼Œä¸Šä¼ åˆ°è‡ªå·±çš„å‘é‡æ•°æ®åº“
#'''
#é¦–å…ˆè¿›å…¥æ–‡ä»¶å¤¹æŸ¥çœ‹æ•°æ®
directory_path = 'dental_data' #è¿™è¾¹å¡«å…¥ä½ è‡ªå·±çš„æ•°æ®æ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶å¤¹
data = []
# loop through each file in the directory
for filename in os.listdir(directory_path):
    # check if the file is a doc or docx file
    # æ£€æŸ¥æ‰€æœ‰docä»¥åŠdocxåç¼€çš„æ–‡ä»¶
    if filename.endswith(".doc") or filename.endswith(".docx"):
        # print the file name
        # langchainè‡ªå¸¦åŠŸèƒ½ï¼ŒåŠ è½½wordæ–‡æ¡£
        loader = UnstructuredWordDocumentLoader(f'{directory_path}/{filename}')
        print(loader)
        data.append(loader.load())
print(len(data))
#Chunking the data into smaller pieces
#å†ç”¨èœåˆ€æŠŠæ–‡æ¡£åˆ†éš”å¼€ï¼Œchunk_sizeå°±æ˜¯æˆ‘ä»¬è¦åˆ‡å¤šå¤§ï¼Œå»ºè®®è®¾ç½®700åŠä»¥ä¸‹ï¼Œå› ä¸ºopenaiæœ‰å­—æ•°é™åˆ¶ï¼Œchunk_overlapå°±æ˜¯é‡å¤ä¸Šä¸‹æ–‡å¤šå°‘ä¸ªå­—
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)
texts = []
for i in range(len(data)):
    print(i)
    texts.append(text_splitter.split_documents(data[i]))
    print(text_splitter.split_documents(data[i]))
print(len(texts))

#Creating embeddings
# æŠŠæ–‡å­—è½¬æˆæ•°å­—
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# initialize pinecone
# æŠŠæ•°å­—æ”¾è¿›å‘é‡æ•°æ®åº“ï¼Œenvironmentå¡«å†™ä½ çš„æ•°æ®åº“æ‰€åœ¨çš„ä½ç½®ï¼Œä¾‹å¦‚useast
pinecone.init(
    api_key=PINECONE_API_KEY,
    environment=PINECONE_API_ENV
)
# è¦å¡«å…¥å¯¹åº”çš„index name
index_name = "dental-index" # put in the name of your pinecone index here
for i in range(len(texts)):
    Pinecone.from_texts([t.page_content for t in texts[i]], embeddings, index_name=index_name)
    print("done")


'''
å­˜å‚¨å®Œæˆå‘é‡æ•°æ®åº“ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿è¡Œä¸‹é¢çš„ä»£ç ï¼Œç”¨streamlitå¸®æˆ‘ä»¬åšä¸€ä¸ªç®€å•çš„ç½‘é¡µå¯ä»¥ç”¨æ¥è°ƒç”¨æˆ‘ä»¬çš„æœºå™¨äººé—®ç­”
'''
# App framework
# å¦‚ä½•åˆ›å»ºè‡ªå·±çš„ç½‘é¡µæœºå™¨äºº
st.title('å¥ˆè‰¾æ–¯AIç‰™åŒ»ğŸ©ºğŸ¦·') #ç”¨streamlit appåˆ›å»ºä¸€ä¸ªæ ‡é¢˜
# åˆ›å»ºä¸€ä¸ªè¾“å…¥æ å¯ä»¥è®©ç”¨æˆ·å»è¾“å…¥é—®é¢˜
query = st.text_input('æ¬¢è¿æ¥åˆ°å¥ˆè‰¾æ–¯AIç‰™ç§‘è¯Šæ‰€,ä½ å¯ä»¥é—®æˆ‘å…³äºç‰™ç§‘çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šæ´—ä¸€æ¬¡ç‰™å¤šå°‘é’±ï¼Ÿ')

my_bar = st.progress(0, text='ç­‰å¾…æŠ•å–‚é—®é¢˜å“¦')
# initialize search
# å¼€å§‹æœç´¢ï¼Œè§£ç­”
if query:
    pinecone.init(
        api_key=PINECONE_API_KEY,
        environment=PINECONE_API_ENV
    )
    #llmæ˜¯ç”¨æ¥å®šä¹‰è¯­è¨€æ¨¡å‹ï¼Œåœ¨ä¸‹é¢çš„ä¾‹å­ï¼Œç”¨çš„æ˜¯openaiï¼Œæ³¨æ„ï¼Œæ­¤openaiè°ƒç”¨çš„æ˜¯langchainæ–¹æ³•ä¸æ˜¯openaiæœ¬ai
    llm = OpenAI(temperature=0, max_tokens=-1, openai_api_key=OPENAI_API_KEY)
    print('1:'+ str(llm))
    my_bar.progress(10, text='æ­£åœ¨æŸ¥è¯¢å¥ˆè‰¾æ–¯AIæ™ºåº“')
    # embeddingå°±æ˜¯æŠŠæ–‡å­—å˜æˆæ•°å­—
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    print('2:'+ str(embeddings))
    # è°ƒç”¨pineconeçš„æ•°æ®åº“ï¼Œå¼€å§‹æŸ¥è¯¢ä»»åŠ¡
    docsearch = Pinecone.from_existing_index('dental',embedding=embeddings)
    print('3:'+ str(docsearch))
    # ç›¸ä¼¼åº¦æœç´¢ï¼Œä¾‹å¦‚ç–¼678ï¼Œç—›679ï¼Œæœç´¢ç”¨æˆ·çš„é—®é¢˜çš„ç›¸ä¼¼åº¦
    docs = docsearch.similarity_search(query, k=3)
    print('4:'+ str(docs))
    my_bar.progress(60, text='æ‰¾åˆ°ç‚¹å¤´ç»ªäº†')
    # è°ƒç”¨langchainçš„load qaåŠæ³•ï¼Œâ€™stuffâ€˜ä¸ºä¸€ç§æ”¾å…¥openaiçš„åŠæ³•
    chain = load_qa_chain(llm, chain_type='stuff', verbose=True)
    print('5:'+ str(chain))
    my_bar.progress(90, text='å¯ä»¥å¼€å§‹ç”Ÿæˆç­”æ¡ˆäº†ï¼Œè„‘ç»†èƒåœ¨ç‡ƒçƒ§')
    # å¾—åˆ°ç­”æ¡ˆ
    answer = chain.run(input_documents=docs, question=query, verbose=True)
    print('6:'+ str(answer))
    my_bar.progress(100, text='å¥½äº†ikun')
    st.write(answer)
    audio = gtts.gTTS(answer, lang='zh')
    audio.save("audio.wav")
    st.audio('audio.wav', start_time=0)
    os.remove("audio.wav")

# '''
# ä»¥ä¸‹ä»£ç åˆ é™¤æ‰€æœ‰indexesæ¨¡å—ï¼Œé»˜è®¤æ³¨é‡Šå…³é—­ï¼Œè°¨æ…ä½¿ç”¨
# '''
# Are you sure you want to delete this? If yes, delete this line of code
# # deleting all indexes
# pinecone.init(
#     api_key=PINECONE_API_KEY,
#     environment=PINECONE_API_ENV
# )
# pinecone.Index('dental').delete(delete_all=True)
